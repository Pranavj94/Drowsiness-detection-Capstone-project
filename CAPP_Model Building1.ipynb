{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "Uy5WUAiP4PKF",
    "outputId": "83dfdf2d-b24a-474f-ef21-20bc821ab7e2"
   },
   "outputs": [],
   "source": [
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "myM69mom6JmE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SqExTCJnnN0z"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import (Conv2D, MaxPooling3D, Conv3D,\n",
    "    MaxPooling2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zcV406xQ4uxv"
   },
   "outputs": [],
   "source": [
    "#from keras.applications.inception_v3 import InceptionV3\n",
    "input_tensor = Input(shape=(125, 125,3))  # this assumes K.image_data_format() == 'channels_last'\n",
    "model1 = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=True)\n",
    "model1.layers.pop()\n",
    "model1.outputs = [model1.layers[-1].output]\n",
    "model1.output_layers = [model1.layers[-1]]\n",
    "model1.layers[-1].outbound_nodes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim(a):\n",
    "    if not type(a) == list:\n",
    "        return []\n",
    "    return [len(a)] + dim(a[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For ind videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "im0G63ObBzFk",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [40, 2048]\n",
      "2 [40, 2048]\n",
      "3 [40, 2048]\n",
      "4 [40, 2048]\n",
      "5 [40, 2048]\n",
      "6 [40, 2048]\n",
      "7 [40, 2048]\n",
      "8 [40, 2048]\n",
      "9 [40, 2048]\n",
      "10 [40, 2048]\n",
      "11 [40, 2048]\n",
      "12 [40, 2048]\n",
      "13 [40, 2048]\n",
      "14 [40, 2048]\n",
      "15 [40, 2048]\n",
      "16 [40, 2048]\n",
      "17 [40, 2048]\n",
      "18 [40, 2048]\n",
      "19 [40, 2048]\n",
      "20 [40, 2048]\n",
      "21 [40, 2048]\n",
      "22 [40, 2048]\n",
      "23 [40, 2048]\n",
      "24 [40, 2048]\n",
      "25 [40, 2048]\n",
      "26 [40, 2048]\n",
      "27 [40, 2048]\n",
      "28 [40, 2048]\n",
      "29 [40, 2048]\n",
      "30 [40, 2048]\n",
      "31 [40, 2048]\n",
      "32 [40, 2048]\n",
      "33 [40, 2048]\n",
      "34 [40, 2048]\n",
      "35 [40, 2048]\n",
      "36 [40, 2048]\n",
      "37 [40, 2048]\n",
      "38 [40, 2048]\n",
      "39 [40, 2048]\n",
      "40 [40, 2048]\n",
      "41 [40, 2048]\n",
      "42 [40, 2048]\n",
      "43 [40, 2048]\n",
      "44 [40, 2048]\n",
      "45 [40, 2048]\n",
      "46 [40, 2048]\n",
      "47 [40, 2048]\n",
      "48 [40, 2048]\n",
      "49 [40, 2048]\n",
      "50 [40, 2048]\n",
      "51 [40, 2048]\n",
      "52 [40, 2048]\n",
      "53 [40, 2048]\n",
      "54 [40, 2048]\n",
      "55 [40, 2048]\n",
      "56 [40, 2048]\n",
      "57 [40, 2048]\n",
      "58 [40, 2048]\n",
      "59 [40, 2048]\n",
      "60 [40, 2048]\n",
      "61 [40, 2048]\n",
      "62 [40, 2048]\n",
      "63 [40, 2048]\n",
      "64 [40, 2048]\n",
      "65 [40, 2048]\n",
      "66 [40, 2048]\n",
      "67 [40, 2048]\n",
      "68 [40, 2048]\n",
      "69 [40, 2048]\n",
      "70 [40, 2048]\n",
      "71 [40, 2048]\n",
      "72 [40, 2048]\n",
      "73 [40, 2048]\n",
      "74 [40, 2048]\n",
      "75 [40, 2048]\n",
      "76 [40, 2048]\n",
      "77 [40, 2048]\n",
      "78 [40, 2048]\n",
      "79 [40, 2048]\n",
      "80 [40, 2048]\n",
      "81 [40, 2048]\n",
      "82 [40, 2048]\n",
      "83 [40, 2048]\n",
      "84 [40, 2048]\n",
      "85 [40, 2048]\n",
      "86 [40, 2048]\n",
      "87 [40, 2048]\n",
      "88 [40, 2048]\n",
      "89 [40, 2048]\n",
      "90 [40, 2048]\n",
      "91 [40, 2048]\n",
      "92 [40, 2048]\n",
      "93 [40, 2048]\n",
      "94 [40, 2048]\n",
      "95 [40, 2048]\n",
      "96 [40, 2048]\n",
      "97 [40, 2048]\n",
      "98 [40, 2048]\n",
      "99 [40, 2048]\n",
      "100 [40, 2048]\n",
      "101 [40, 2048]\n",
      "102 [40, 2048]\n",
      "103 [40, 2048]\n",
      "104 [40, 2048]\n",
      "105 [40, 2048]\n",
      "106 [40, 2048]\n",
      "107 [40, 2048]\n",
      "108 [40, 2048]\n",
      "109 [40, 2048]\n",
      "110 [40, 2048]\n",
      "111 [40, 2048]\n",
      "112 [40, 2048]\n"
     ]
    }
   ],
   "source": [
    "active_drowsy=['E:/CAPP/Active/Images/','E:/CAPP/Drowzy/Images/']\n",
    "count=1\n",
    "for a in active_drowsy:\n",
    "    people=os.listdir(a+'Processing')\n",
    "    for b in people:\n",
    "        frames = [f for f in listdir(a+\"Processing/\"+b) if isfile(join(a+\"Processing/\"+b, f))]\n",
    "        file=[]\n",
    "        for c in frames:\n",
    "            img = cv2.imread(a+\"Processing/\"+b+\"/\"+c)\n",
    "            img=cv2.resize (img,(125,125))\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            prediction=model1.predict(img)\n",
    "            prediction=np.squeeze(prediction)\n",
    "            x_list = prediction.tolist()\n",
    "            file.append(x_list)\n",
    "        print(count,dim(file))\n",
    "        count+=1\n",
    "        X.append(file)\n",
    "        if(a=='E:/CAPP/Active/Images/'):\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 1 min video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/CAPP/1min/Images/Closed/1\n",
      "1 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/10\n",
      "2 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/11\n",
      "3 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/12\n",
      "4 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/13\n",
      "5 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/14\n",
      "6 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/15\n",
      "7 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/16\n",
      "8 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/17\n",
      "9 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/18\n",
      "10 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/19\n",
      "11 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/2\n",
      "12 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/20\n",
      "13 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/21\n",
      "14 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/22\n",
      "15 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/23\n",
      "16 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/24\n",
      "17 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/25\n",
      "18 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/26\n",
      "19 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/27\n",
      "20 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/28\n",
      "21 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/29\n",
      "22 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/3\n",
      "23 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/30\n",
      "24 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/31\n",
      "25 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/32\n",
      "26 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/33\n",
      "27 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/34\n",
      "28 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/35\n",
      "29 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/36\n",
      "30 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/37\n",
      "31 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/38\n",
      "32 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/39\n",
      "33 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/4\n",
      "34 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/40\n",
      "35 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/41\n",
      "36 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/42\n",
      "37 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/43\n",
      "38 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/44\n",
      "39 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/45\n",
      "40 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/46\n",
      "41 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/47\n",
      "42 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/48\n",
      "43 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/49\n",
      "44 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/5\n",
      "45 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/50\n",
      "46 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/51\n",
      "47 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/52\n",
      "48 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/6\n",
      "49 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/7\n",
      "50 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/8\n",
      "51 [40, 2048]\n",
      "E:/CAPP/1min/Images/Closed/9\n",
      "52 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/1\n",
      "53 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/10\n",
      "54 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/11\n",
      "55 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/12\n",
      "56 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/13\n",
      "57 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/14\n",
      "58 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/15\n",
      "59 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/16\n",
      "60 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/17\n",
      "61 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/18\n",
      "62 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/19\n",
      "63 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/2\n",
      "64 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/20\n",
      "65 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/21\n",
      "66 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/22\n",
      "67 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/23\n",
      "68 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/24\n",
      "69 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/25\n",
      "70 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/26\n",
      "71 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/27\n",
      "72 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/28\n",
      "73 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/29\n",
      "74 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/3\n",
      "75 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/30\n",
      "76 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/31\n",
      "77 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/32\n",
      "78 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/33\n",
      "79 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/34\n",
      "80 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/35\n",
      "81 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/36\n",
      "82 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/37\n",
      "83 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/38\n",
      "84 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/39\n",
      "85 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/4\n",
      "86 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/40\n",
      "87 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/41\n",
      "88 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/42\n",
      "89 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/43\n",
      "90 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/44\n",
      "91 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/45\n",
      "92 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/46\n",
      "93 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/47\n",
      "94 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/48\n",
      "95 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/49\n",
      "96 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/5\n",
      "97 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/50\n",
      "98 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/51\n",
      "99 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/52\n",
      "100 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/6\n",
      "101 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/7\n",
      "102 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/8\n",
      "103 [40, 2048]\n",
      "E:/CAPP/1min/Images/Open/9\n",
      "104 [40, 2048]\n"
     ]
    }
   ],
   "source": [
    "active_drowsy=['E:/CAPP/1min/Images/Closed','E:/CAPP/1min/Images/Open']\n",
    "count=1\n",
    "for a in active_drowsy:\n",
    "    people=os.listdir(a)\n",
    "    for b in people:\n",
    "        frames = [f for f in listdir(a+\"/\"+b) if isfile(join(a+\"/\"+b, f))]\n",
    "        file=[]\n",
    "        print(a+\"/\"+b)\n",
    "        for c in frames:\n",
    "            #print(a+\"/\"+b+\"/\"+c)\n",
    "            img = cv2.imread(a+\"/\"+b+\"/\"+c)\n",
    "            img=cv2.resize (img,(125,125))\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            prediction=model1.predict(img)\n",
    "            prediction=np.squeeze(prediction)\n",
    "            x_list = prediction.tolist()\n",
    "            file.append(x_list)\n",
    "        print(count,dim(file))\n",
    "        count+=1\n",
    "        X.append(file)\n",
    "        if(a=='E:/CAPP/1min/Images/Open'):\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216, 40, 2048)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp=np.asarray(X)\n",
    "#X_temp=np.squeeze(X_temp)\n",
    "X_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_temp=np.asarray(Y)\n",
    "Y_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('E:/CAPP/X_216.npy',X_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('E:/CAPP/Y_216.npy',Y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXECUTE TILL HERE ONLY\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp=X\n",
    "Y_temp=Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.append(X)\n",
    "Y_temp.append(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem=np.asarray(X_temp)\n",
    "tem=np.squeeze(tem)\n",
    "tem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#active_drowsy=['E:/CAPP/Active/Images/','E:/CAPP/Drowzy/Images/']\n",
    "a='E:/CAPP/Drowzy/Images/'\n",
    "people=os.listdir(a+'Processing')\n",
    "for b in people:\n",
    "    frames = [f for f in listdir(a+\"Processing/\"+b) if isfile(join(a+\"Processing/\"+b, f))]\n",
    "    file=[]\n",
    "    for c in frames:\n",
    "        img = cv2.imread(a+\"Processing/\"+b+\"/\"+c)\n",
    "        img=cv2.resize (img,(125,125))\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        prediction=model1.predict(img)\n",
    "        prediction=np.squeeze(prediction)\n",
    "        x_list = prediction.tolist()\n",
    "        file.append(x_list)\n",
    "    X.append(file)\n",
    "    if(a=='E:/CAPP/Active/Images/'):\n",
    "        Y.append(0)\n",
    "    else:\n",
    "        Y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "i7IikwqYBzL9",
    "outputId": "405a4633-1dda-475b-8c35-963d3b57ad07"
   },
   "outputs": [],
   "source": [
    "X1=np.asarray(X)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z4Kud_gQBzPL",
    "outputId": "b79ece63-9f43-4948-eec7-96bfaccd3873"
   },
   "outputs": [],
   "source": [
    "Y1=np.asarray(Y)\n",
    "Y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "CtUyVv4kmosq",
    "outputId": "0df38329-451d-4bb6-f7a4-bbab598bb0bd"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(2048, return_sequences=True,input_shape=(40,2048),dropout=0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.00005),\n",
    "metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "colab_type": "code",
    "id": "COVd-LWlmozF",
    "outputId": "c873a8d6-fe13-4b94-a7f7-acfd4787d0fa"
   },
   "outputs": [],
   "source": [
    "model.fit(X1,Y1,epochs=10,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "dl9NsDPUmo1k",
    "outputId": "1f804dff-95de-470c-aafb-eaee6fd6261c"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zEiKThLoBzS0"
   },
   "outputs": [],
   "source": [
    "model.save('Trial_clob_1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "URj2DemCBzVC",
    "outputId": "062d438a-4368-4b4e-c9cf-904fb055840f"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iyDSpWVFo7DT"
   },
   "outputs": [],
   "source": [
    "# 1. Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A9KxswQYo7FU"
   },
   "outputs": [],
   "source": [
    "# create on Colab directory\n",
    "model.save('Trial_clob_1.h5')  \n",
    "model_file = drive.CreateFile({'title' : 'Trial_clob_1.h5'})\n",
    "model_file.SetContentFile('Trial_clob_1.h5')\n",
    "model_file.Upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPIhui_N-ZTS"
   },
   "source": [
    "Impementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bvqFPxIB9_vX",
    "outputId": "3694572e-0346-4a0d-c7cd-947d623a00ad"
   },
   "outputs": [],
   "source": [
    "#Loading the haar cascade amlifier\n",
    "face_cascade = cv2.CascadeClassifier('/content/drive/My Drive/Capstone/Video/haarcascade_frontalface_alt.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('/content/drive/My Drive/Capstone/Video/haarcascade_mcs_eyepair_big.xml')\n",
    "print(\"Loading haar cascaade eye detector...... \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6BkKxrZB9_yy",
    "outputId": "94861ed2-8230-4282-a99c-aeeef95c1fb5"
   },
   "outputs": [],
   "source": [
    "#Loading inception v3\n",
    "input_tensor = Input(shape=(125, 125,3))  # this assumes K.image_data_format() == 'channels_last'\n",
    "model1 = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=True)\n",
    "model1.layers.pop()\n",
    "model1.outputs = [model1.layers[-1].output]\n",
    "model1.output_layers = [model1.layers[-1]]\n",
    "model1.layers[-1].outbound_nodes = []\n",
    "print('Loading inception v3......')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tqYHNNFE9_08",
    "outputId": "4a7d83df-5435-43fc-84f6-01a4ea5dfe6d"
   },
   "outputs": [],
   "source": [
    "frame_list=[]\n",
    "\n",
    "#Reading the frames, passing through haar and iterating through each frame\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture('http://192.168.0.108:8080/video')\n",
    "count=1\n",
    "ret=1\n",
    "while ret:\n",
    "    ret, img = cap.read()\n",
    "    if ret==0:\n",
    "      print(\"PADACHONE..PANI PAALI\")\n",
    "      break\n",
    "    gray = cv2.cvtColor(img,0)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.2, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_color)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            crop_img = roi_color[ey: ey + eh, ex: ex + ew]\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "            crop_img=cv2.resize (crop_img,(125,125))\n",
    "            crop_img = np.expand_dims(crop_img, axis=0)\n",
    "    \n",
    "    \n",
    "            prediction1=model1.predict(crop_img)\n",
    "            prediction1=np.squeeze(prediction1)\n",
    "            x_list = prediction1.tolist()\n",
    "            frame_list.append(x_list)\n",
    "            if (len(frame_list)>=40):\n",
    "                X=[]\n",
    "                X.append(frame_list)\n",
    "                X=np.asarray(X)\n",
    "                print(X.shape)\n",
    "                frame_list=frame_list[4:]\n",
    "                prediction=model.predict(X)\n",
    "                print(prediction)\n",
    "                for j in prediction:\n",
    "                    if j[1]>j[0]:\n",
    "                      print(\"Jabba\")\n",
    "                    else:\n",
    "                      print(\"Andi\")\n",
    "                        #cv2.imshow(\"Driver is drowsy\", frame)\n",
    "                        #duration = 10  # second\n",
    "                        #freq = 440  # Hz\n",
    "                        #os.system('play --no-show-progress --null --channels 1 synth %s sine %f' % (duration, freq))\n",
    "                      \n",
    "    #k = cv2.waitKey(1) & 0xff\n",
    "    #if k == ord(\"q\"):\n",
    "    #    break\n",
    "   \n",
    "cap.release()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iaqN92aD9_3X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pSOBNgji9_7x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "wyXsz_us9_54",
    "outputId": "a357834c-5afc-4cba-b779-61d33d72e928"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('/content/drive/My Drive/Capstone/Video/Deepak.mp4')\n",
    "ret, img = cap.read()\n",
    "cv2.imshow(\"Test\", img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ENp66xkR9_s5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
